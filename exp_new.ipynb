{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 检查可用GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current GPU device:  5\n",
      "Number of available GPUs: 8\n",
      "Device 0: NVIDIA GeForce RTX 3090\n",
      "Device 1: NVIDIA GeForce RTX 3090\n",
      "Device 2: NVIDIA GeForce RTX 3090\n",
      "Device 3: NVIDIA GeForce RTX 3090\n",
      "Device 4: NVIDIA GeForce RTX 3090\n",
      "Device 5: NVIDIA GeForce RTX 3090\n",
      "Device 6: NVIDIA GeForce RTX 3090\n",
      "Device 7: NVIDIA GeForce RTX 3090\n",
      "GPU 0: 82 cores\n",
      "GPU 1: 82 cores\n",
      "GPU 2: 82 cores\n",
      "GPU 3: 82 cores\n",
      "GPU 4: 82 cores\n",
      "GPU 5: 82 cores\n",
      "GPU 6: 82 cores\n",
      "GPU 7: 82 cores\n",
      "cwd:/home/lihaiyue/data/snapshotscope/replicate/exp/fouriernet_mse_3000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# 检查CUDA是否可用\n",
    "if torch.cuda.is_available():\n",
    "    # 获取当前正在使用的GPU设备\n",
    "    torch.cuda.set_device(5)\n",
    "    device = torch.cuda.current_device()\n",
    "    print(\"Current GPU device: \", device)\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {device_count}\")\n",
    "\n",
    "    # 获取每个GPU的名称\n",
    "    for i in range(device_count):\n",
    "        device_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"Device {i}: {device_name}\")\n",
    "else:\n",
    "    print(\"No CUDA devices available\")\n",
    "\n",
    "for i in range(device_count):\n",
    "    properties = torch.cuda.get_device_properties(i)\n",
    "    print(f\"GPU {i}: {properties.multi_processor_count} cores\")\n",
    "\n",
    "print(f\"cwd:{os.getcwd()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. import 需用模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.cuda.comm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.cuda._utils import _get_device_index\n",
    "from collections import OrderedDict\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/lihaiyue/data/snapshotscope/replicate')\n",
    "from utils.control import *\n",
    "from utils.output_control import *\n",
    "from utils.networks import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset创建函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DiffuserMirflickrDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for loading pairs of diffused images collected through DiffuserCam\n",
    "    and ground truth, unblurred images collected through a DSLR camera. For use\n",
    "    with DLMD (DiffuserCam Lensless Mirflickr Dataset). Optionally supports any\n",
    "    callable transform.\n",
    "\n",
    "    Args:\n",
    "        csv_path: Path to .csv file containing filenames of images (both\n",
    "        diffused and ground truth images share the same filename).\n",
    "\n",
    "        data_dir: Path to directory containing diffused image data.\n",
    "\n",
    "        label_dir: Path to directory containing ground truth image data.\n",
    "\n",
    "        transform (optional): An optional callable that will be applied to\n",
    "        every image pair. Defaults to None, in which case nothing happens.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, data_dir, label_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.csv_contents = pd.read_csv(csv_path)\n",
    "        self.data_dir = data_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv_contents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = self.csv_contents.iloc[idx, 0]\n",
    "\n",
    "        path_diffused = os.path.join(self.data_dir, img_name)\n",
    "        path_gt = os.path.join(self.label_dir, img_name)\n",
    "\n",
    "        #image = np.load(path_diffused[0:-9] + \".npy\") \n",
    "        image = np.load(path_diffused+ \".npy\") \n",
    "        #label = np.load(path_gt[0:-9] + \".npy\")\n",
    "        label = np.load(path_gt + \".npy\")\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        label = label.transpose((2, 0, 1))\n",
    "        image = torch.from_numpy(image)\n",
    "        label = torch.from_numpy(label)\n",
    "\n",
    "        sample = {\"image\": image, \"label\": label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行基础设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices=[5]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(filename=\"out.log\", level=logging.DEBUG, format=\"%(message)s\")\n",
    "\n",
    "# define optimization hyperparameters\n",
    "learning_rate = 1e-4\n",
    "lpips_weight = 0\n",
    "lpips_step_size = 0.1\n",
    "lpips_step_milestones = []\n",
    "num_iterations = 3000\n",
    "\n",
    "# setup the simulation parameters, make a microscope\n",
    "image_shape = (1080, 1920)\n",
    "num_chunks = 1\n",
    "devices = [torch.cuda.current_device()]\n",
    "print(f\"devices={devices}\")\n",
    "\n",
    "# calculate downsampled sizes\n",
    "downsample = 4\n",
    "downsampled_image_shape = [int(s / downsample) for s in image_shape]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入各个待用模块的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reconstruction_network():\n",
    "    # create multi gpu reconstruction network list for 1 gpu\n",
    "    deconv = FourierNetRGB(\n",
    "        20, \n",
    "        downsampled_image_shape,\n",
    "        fourier_conv_args={\"stride\": 2},\n",
    "        conv_kernel_sizes=[(11, 11), (11, 11), (11, 11)],\n",
    "        conv_fmap_nums=[64, 64, 3],\n",
    "        input_scaling_mode=None,\n",
    "        device=devices[0],\n",
    "    )\n",
    "    return deconv\n",
    "\n",
    "def initialize_reconstruction(latest=None):\n",
    "    deconv = create_reconstruction_network()\n",
    "    if latest is not None:\n",
    "        print(\"[info] loading from checkpoint\")\n",
    "        deconv.load_state_dict(latest[\"deconv_state_dict\"], strict=True) \n",
    "    return deconv\n",
    "\n",
    "def initialize_optimizer(deconv, latest=None):\n",
    "    # optimize microscope parameters and reconstruction network\n",
    "    opt = optim.Adam(\n",
    "        [{\"params\": deconv.parameters(), \"lr\": learning_rate}], lr=learning_rate\n",
    "    ) #parameters()再研究下\n",
    "    if latest is not None:\n",
    "        opt.load_state_dict(latest[\"opt_state_dict\"])\n",
    "    return opt\n",
    "\n",
    "def create_dataset(test=False):\n",
    "    base_path = \"/home/lihaiyue/data/snapshotscope/data/dlmd/dataset\"\n",
    "    data_dir = os.path.join(base_path, \"diffuser_images\")\n",
    "    label_dir = os.path.join(base_path, \"ground_truth_lensed\")\n",
    "    if not test:\n",
    "        csv_path = os.path.join(base_path, \"dataset_train.csv\")\n",
    "        dataset = DiffuserMirflickrDataset(csv_path, data_dir, label_dir)\n",
    "    else:\n",
    "        csv_path = os.path.join(base_path, \"dataset_test.csv\")\n",
    "        dataset = DiffuserMirflickrDataset(csv_path, data_dir, label_dir) \n",
    "    return dataset\n",
    " #DiffuserMirflickrDataset 模块在dataloader.py中，返回dic：sample = {\"image\": image, \"label\": label}，image，label均为torch\n",
    "\n",
    "def create_dataloader(dataset, test=False):\n",
    "    if not test:\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, num_workers=10, batch_size=30, shuffle=True #num_workers用于指定在加载数据时使用的子进程数\n",
    "        )\n",
    "    else:\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            dataset, num_workers=4, batch_size=1, shuffle=False #test dataloader的batch size必须为1\n",
    "        )\n",
    "    return dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练！"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model for training\n",
    "if os.path.exists(\"latest.pt\"):\n",
    "    latest = torch.load(\"latest.pt\")\n",
    "else:\n",
    "    latest = None\n",
    "deconv = initialize_reconstruction(latest=latest)\n",
    "print(deconv)\n",
    "\n",
    "# initialize optimizer\n",
    "opt = initialize_optimizer(deconv, latest=latest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data \n",
    "dataset = create_dataset()\n",
    "#TODO：change split numbers\n",
    "dataset, val_dataset = torch.torch.utils.data.random_split(\n",
    "    dataset, [900, 12], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "dataloader = create_dataloader(dataset) \n",
    "val_dataloader = create_dataloader(val_dataset, test=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize iteration count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize iteration count\n",
    "if latest is not None:\n",
    "    latest_iter = latest[\"it\"]\n",
    "    mses = latest[\"mses\"]\n",
    "    #lpips_losses = latest[\"lpips_losses\"]\n",
    "    validate_mses = latest[\"validate_mses\"]\n",
    "else:\n",
    "    latest_iter = 0\n",
    "    mses = []\n",
    "    #lpips_losses = []\n",
    "    validate_mses = []\n",
    "\n",
    "# initialize iteration count\n",
    "it = int(latest_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove loaded checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove loaded checkpoint\n",
    "if latest is not None:\n",
    "    del latest\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create folder for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for validation data(会建在exp.ipynb同一个文件夹下)\n",
    "if not os.path.exists(\"snapshots/validate/\"):\n",
    "    os.makedirs(\"snapshots/validate/\")\n",
    "val_dir = \"snapshots/validate/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run psf training\n",
    "train_rgb_recon(\n",
    "    deconv,\n",
    "    opt,\n",
    "    dataloader,\n",
    "    devices,\n",
    "    mses,\n",
    "    num_iterations,\n",
    "    lpips_weight=lpips_weight,\n",
    "    lpips_step_milestones=lpips_step_milestones,\n",
    "    lpips_step_size=lpips_step_size,\n",
    "    checkpoint_interval = 20,\n",
    "    snapshot_interval = 60,\n",
    "    validate_mses=validate_mses,\n",
    "    validate_args={\n",
    "        \"dataloader\": val_dataloader,\n",
    "        \"devices\": devices,\n",
    "        \"save_dir\": val_dir,\n",
    "    },\n",
    "    it=it,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] loading from checkpoint\n",
      "Sequential(\n",
      "  (fourier_conv): FourierConv2D(3, 20, kernel_size=[270, 480])\n",
      "  (fourier_relu): LeakyReLU(negative_slope=0.01)\n",
      "  (fourier_bn): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2d_1): Conv2d(20, 64, kernel_size=(11, 11), stride=(1, 1), padding=[5, 5])\n",
      "  (conv1_relu): LeakyReLU(negative_slope=0.01)\n",
      "  (conv1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2d_2): Conv2d(64, 64, kernel_size=(11, 11), stride=(1, 1), padding=[5, 5])\n",
      "  (conv2_relu): LeakyReLU(negative_slope=0.01)\n",
      "  (conv2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2d_3): Conv2d(64, 3, kernel_size=(11, 11), stride=(1, 1), padding=[5, 5])\n",
      "  (conv3_relu): ReLU()\n",
      ")\n",
      "16226175\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lihaiyue/data/snapshotscope/replicate/utils/networks.py:170: UserWarning: The function torch.fft is deprecated and will be removed in PyTorch 1.8. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.fftn. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:567.)\n",
      "  fourier_im = torch.fft(F.pad(im.unsqueeze(-1), pad_size), 2)\n",
      "/home/lihaiyue/data/snapshotscope/replicate/utils/networks.py:184: UserWarning: The function torch.ifft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.ifftn. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:578.)\n",
      "  real_feats = torch.ifft(fourier_feats, 2).index_select(-1, indices)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "mse=0.012008828052785248\n",
      " lpips=-0.004603580688126385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # initialize model for training\n",
    "    if os.path.exists(\"latest.pt\"):\n",
    "        latest = torch.load(\"snapshots/state2999.pt\")  #TODO:change load state\n",
    "    else:\n",
    "        latest = None\n",
    "    deconv = initialize_reconstruction(latest=latest)\n",
    "    deconv.eval()\n",
    "    print(deconv)\n",
    "    num_params = sum([p.view(-1).shape[0] for p in deconv.parameters()])\n",
    "    print(num_params)\n",
    "\n",
    "    # initialize data\n",
    "    dataset = create_dataset(test=True)\n",
    "    dataloader = create_dataloader(dataset, test=True)\n",
    "\n",
    "    # remove loaded checkpoint\n",
    "    if latest is not None:\n",
    "        del latest\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # initialize results storage folder\n",
    "    if not os.path.exists(f'./test'):\n",
    "        os.mkdir(f'./test')\n",
    "    save_dir = f'./test'\n",
    "\n",
    "    losses=test_rgb_recon(deconv, dataloader, devices, save_dir=save_dir)\n",
    "\n",
    "    return losses\n",
    "\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
